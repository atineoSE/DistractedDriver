{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nnp.random.seed(42)\nimport tensorflow as tf\ntf.set_random_seed(42)\nfrom keras.models import Model\nfrom keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nimport os\nprint(os.listdir(\"../input/\"))\nfrom PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1d96a19dcb6fc6c233e0700b8e384f37cd9ec81"},"cell_type":"code","source":"# Create a class to store global variables. Easier for adjustments.\nclass Configuration:\n    def __init__(self):\n        self.epochs = 10\n        self.batch_size = 16\n        self.maxwidth =0\n        self.maxheight=0\n        self.minwidth = 35000\n        self.minheight = 35000\n        self.imgcount=0\n        self.img_width_adjust = 480\n        self.img_height_adjust= 360\n        #Kaggle\n        self.data_dir = \"../input/train/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54150e8b0d6c128fdf4afdfab73062ca66fc0d7a"},"cell_type":"code","source":"config = Configuration()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"702d07cf0cc20061b45bc973e5407928475b2c6b"},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{"trusted":true,"_uuid":"4fc955a4e07e38178e31c323f07a6d7e6784c064"},"cell_type":"code","source":"#Load an example photo\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimg=mpimg.imread('../input/train/c0/img_4013.jpg')\nimgplot = plt.imshow(img)\nimg.shape\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53c1038d354f7181f359cd457d4be1e071e0d13a"},"cell_type":"code","source":"#Find the largest and smallest dimensions of all the pictures\ndef findPictureDims(path):\n    for subdir, dirs, files in os.walk(path):\n        for file in files:\n            if file.endswith(\".jpg\"):\n                config.imgcount+=1\n                filename = os.path.join(subdir, file)\n                image = Image.open(filename)\n                width, height = image.size\n                if width < config.minwidth:\n                    config.minwidth = width\n                if height < config.minheight:\n                    config.minheight = height\n                if width > config.maxwidth:\n                    config.maxwidth = width\n                if height > config.maxheight:\n                    config.maxheight = height\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3be8cb99a1a8968a830644d7dc5b86cdc84cef4"},"cell_type":"code","source":"#Count the number of files in each subdirectory\ndef listDirectoryCounts(path):\n    d = []\n    for subdir, dirs, files in os.walk(path,topdown=False):\n        filecount = len(files)\n        dirname = subdir\n        d.append((dirname,filecount))\n    return d ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"561fa4c2604e3889e2f67d47f54038555c0325ac"},"cell_type":"code","source":"def SplitCat(df):\n    for index, row in df.iterrows():\n        directory=row['Category'].split('/')\n        if directory[3]!='':\n            directory=directory[3]\n            df.at[index,'Category']=directory\n        else:\n            df.drop(index, inplace=True)\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2cdcd1eb41511104f8f15da2d90c3b49b853163"},"cell_type":"code","source":"#Get image count per category\ndirCount=listDirectoryCounts(config.data_dir)\ncategoryInfo = pd.DataFrame(dirCount, columns=['Category','Count'])\nSplitCat(categoryInfo)\ncategoryInfo=categoryInfo.sort_values(by=['Category'])\nprint(categoryInfo.to_string(index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"582670bd9d4264c1bfac717b50e7d69d2e9a5a04"},"cell_type":"code","source":"#Print out mins and maxes and the image counts\nfindPictureDims(config.data_dir)\nprint(\"Minimum Width:\\t\",config.minwidth, \"\\tMinimum Height:\",config.minheight)\nprint(\"Maximum Width:\\t\",config.maxwidth, \"\\tMaximum Height:\",config.maxheight, \"\\tImage Count:\\t\",config.imgcount)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1b3ed8662e9df6aa583a10fe3013d8d23fd80d2"},"cell_type":"markdown","source":"## Analysis\n-All of the data in the training directory is of the same height and width.\n-The aspect ratio of the pictures is 4:3, so any adjustments are made should be close to that ratio (see configuration)\n"},{"metadata":{"_uuid":"c4ed284de147265f748d7d8af6431a650a5c2011"},"cell_type":"markdown","source":"## Building the Model"},{"metadata":{"trusted":true,"_uuid":"e476f2d5bb7c4c607dc76bb6b88b19b92a0c951a"},"cell_type":"code","source":"#Model Definition\ndef build_model():\n    inputs = Input(shape=(config.img_width_adjust,config.img_height_adjust,3), name=\"input\")\n    \n    #Convolution 1\n    conv1 = Conv2D(128, kernel_size=(3,3), activation=\"relu\", name=\"conv_1\")(inputs)\n    pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool_1\")(conv1)\n\n    #Convolution 2\n    conv2 = Conv2D(64, kernel_size=(3,3), activation=\"relu\", name=\"conv_2\")(pool1)\n    pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool_2\")(conv2)\n    \n    #Convolution 3\n    conv3 = Conv2D(32, kernel_size=(3,3), activation=\"relu\", name=\"conv_3\")(pool2)\n    pool3 = MaxPooling2D(pool_size=(2, 2), name=\"pool_3\")(conv3)\n    \n    #Convolution 4\n    conv4 = Conv2D(16, kernel_size=(3,3), activation=\"relu\", name=\"conv_4\")(pool3)\n    pool4 = MaxPooling2D(pool_size=(2, 2), name=\"pool_4\")(conv4)\n    \n    #Fully Connected Layer\n    flatten = Flatten()(pool4)\n    fc1 = Dense(1024, activation=\"relu\", name=\"fc_1\")(flatten)\n    \n    #output\n    output=Dense(10, activation=\"softmax\", name =\"softmax\")(fc1)\n    \n    # finalize and compile\n    model = Model(inputs=inputs, outputs=output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f922f1983c7cc07ce5bc58de162bf8d166d3f53e"},"cell_type":"code","source":"#Setup data, and create split for training, testing 80/20\ndef setup_data(train_data_dir, val_data_dir, img_width=config.img_width_adjust, img_height=config.img_height_adjust, batch_size=config.batch_size):\n    \n    train_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n    \n\n    train_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='training')\n    \n    validation_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='validation')\n        #Note uses training dataflow generator\n    return train_generator, validation_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aaa0faa3125d69a32543ec2b9d29172b4abd699"},"cell_type":"code","source":"def fit_model(model, train_generator, val_generator, batch_size, epochs):\n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=train_generator.samples // batch_size,\n        epochs=epochs,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples // batch_size,\n        verbose=1)\n    return model\n\n#Verbose: 0: no output, 1: output with status bar, 2: Epochs Only","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e586e934a338b19bfc0503c05a6f9a9cbb1ce2ae"},"cell_type":"code","source":"# Model Evaluation\ndef eval_model(model, val_generator, batch_size):\n    scores = model.evaluate_generator(val_generator, steps=val_generator.samples // batch_size)\n    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecddb906eaad5e251a6dbdbe78ef9b6632dbf10d"},"cell_type":"code","source":"# Create Data 80/20\ntrain_generator, val_generator = setup_data(config.data_dir, config.data_dir, batch_size=config.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"424104dfb9b8ba643de5c192ab2e677e1a192aed"},"cell_type":"code","source":"# Build the model and show the summary data (note trainable parameters)\nmodel = build_model()\nprint (model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d377f9d1942f811ceb19333fcedda8ae4b4305e"},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true,"_uuid":"80f89a80b8f2b635ebea7d8b850a7d45e7d59ebf"},"cell_type":"code","source":"# Fit the model, note this takes about 1 hr 40 mins with GPU\nmodel = fit_model(model, train_generator, val_generator,\n                  batch_size=config.batch_size,\n                  epochs=config.epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6757ec2ed464b91730e5c828ff4c2f700f776a0"},"cell_type":"code","source":"# Evaluate your model.\neval_model(model, val_generator, batch_size=config.batch_size)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}